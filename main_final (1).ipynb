{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import shap\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation_names = [\n",
    "    #\"Original\",            # No transformation\n",
    "    # \"PowerTransformer\",    # Uses PowerTransformer (Yeo-Johnson)\n",
    "    # \"Log1p\",               # log(x+1) transformation\n",
    "    # \"Sqrt\",                # Square root transformation\n",
    "    \"BoxCox\"#,              # Box-Cox transformation (with shifting if necessary)\n",
    "    # \"QuantileTransformer\", # Maps data to a normal distribution\n",
    "    # \"Normalization\" \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['X_test_Sqrt', 'y_train', 'y_test', 'X_train_Normalization', 'data', 'X_test_Normalization', 'X_test_BoxCox', 'X_train_Original', 'X_test_PowerTransformer', 'X_train_Log1p', 'X_test_Original', 'X_train_Sqrt', 'X_train_BoxCox', 'X_train_PowerTransformer', 'X_test_Log1p', 'X_test_QuantileTransformer', 'X_train_QuantileTransformer'])\n"
     ]
    }
   ],
   "source": [
    "# Directory containing the CSV files\n",
    "directory = './split_data'\n",
    "\n",
    "# Dictionary to store DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df_name = filename.split('.')[0]  # Use the filename (without extension) as the key\n",
    "        dataframes[df_name] = pd.read_csv(os.path.join(directory, filename))\n",
    "\n",
    "# Display the keys of the dictionary to confirm\n",
    "print(dataframes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for modeling\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.preprocessing import MinMaxScaler # Use MinMaxScaler to prevent negative values\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Define continuous and categorical columns for MixedNaiveBayes\n",
    "continuous_cols = ['BMI', 'MentHlth', 'PhysHlth', 'Age']\n",
    "categorical_cols = [col for col in dataframes['X_train_BoxCox'].columns if col not in continuous_cols]\n",
    "\n",
    "# Custom implementation of Naive Bayes\n",
    "# Use Gaussian distribution to predict continuous variables\n",
    "# Use categorical distribution to predict discrete variables\n",
    "# Combine probabilities for final prediction\n",
    "class MixedNaiveBayes:\n",
    "    def __init__(self, continuous_cols, categorical_cols, priors=None):\n",
    "        self.continuous_cols = continuous_cols\n",
    "        self.categorical_cols = categorical_cols\n",
    "        self.priors = priors\n",
    "        if self.priors is not None:  # If class prior is provided\n",
    "            self.gaussian_nb = GaussianNB(priors=self.priors)\n",
    "            self.categorical_nb = CategoricalNB(fit_prior=False, class_prior=self.priors)\n",
    "        else:\n",
    "            self.gaussian_nb = GaussianNB()\n",
    "            self.categorical_nb = CategoricalNB()\n",
    "        self.has_categorical = False\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        #print(f'Cont cols: {self.continuous_cols}')\n",
    "        #print(f'Cat cols: {self.categorical_cols}')\n",
    "        # Check if there are categorical columns\n",
    "        if len(self.categorical_cols) > 0:\n",
    "            self.has_categorical = True\n",
    "        else:\n",
    "            self.has_categorical = False\n",
    "        #print(f'Has cat: {self.has_categorical}, count: {len(self.categorical_cols)}')\n",
    "\n",
    "        # Split continuous and categorical data\n",
    "        X_continuous = X[self.continuous_cols]\n",
    "        if self.has_categorical:\n",
    "            X_categorical = X[self.categorical_cols]\n",
    "            self.categorical_nb.fit(X_categorical, y)\n",
    "        \n",
    "        # Fit GaussianNB for continuous data\n",
    "        self.gaussian_nb.fit(X_continuous, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Split continuous and categorical data\n",
    "        X_continuous = X[self.continuous_cols]\n",
    "        if self.has_categorical:\n",
    "            X_categorical = X[self.categorical_cols]\n",
    "        \n",
    "        # Predict log probabilities for continuous and categorical data\n",
    "        log_prob_continuous = self.gaussian_nb.predict_log_proba(X_continuous)\n",
    "        log_prob_categorical = np.zeros_like(log_prob_continuous)\n",
    "        if self.has_categorical:\n",
    "            log_prob_categorical = self.categorical_nb.predict_log_proba(X_categorical)\n",
    "        \n",
    "        # Combine log probabilities and predict the class with maximum sum\n",
    "        combined_log_prob = log_prob_continuous + log_prob_categorical\n",
    "        return combined_log_prob.argmax(axis=1)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # Split continuous and categorical data\n",
    "        X_continuous = X[self.continuous_cols]\n",
    "        if self.has_categorical:\n",
    "            X_categorical = X[self.categorical_cols]\n",
    "        \n",
    "        # Predict probabilities for continuous and categorical data\n",
    "        prob_continuous = self.gaussian_nb.predict_proba(X_continuous)\n",
    "        if self.has_categorical:\n",
    "            prob_categorical = self.categorical_nb.predict_proba(X_categorical)\n",
    "            combined_prob = prob_continuous * prob_categorical\n",
    "        else:\n",
    "            combined_prob = prob_continuous\n",
    "        return combined_prob\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return (y_pred == y).mean()\n",
    "\n",
    "# Custom implementation of LinearSVC\n",
    "# Default LinearSVC does NOT support predict_proba()\n",
    "# Scale the decision_function output for binary classification\n",
    "class CalibratedLinearSVC(LinearSVC):\n",
    "    def fit(self, X, y):\n",
    "        super().fit(X, y)\n",
    "        df = self.decision_function(X)\n",
    "        self.df_min_ = df.min()\n",
    "        self.df_max_ = df.max()\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        df = self.decision_function(X)\n",
    "        calibrated_df = (df - self.df_min_) / (self.df_max_ - self.df_min_)\n",
    "        proba_pos_class = np.clip(calibrated_df, 0, 1)\n",
    "        proba_neg_class = 1 - proba_pos_class\n",
    "        proba = np.c_[proba_neg_class, proba_pos_class]\n",
    "        return proba\n",
    "\n",
    "# List of proposed models\n",
    "models = {\n",
    "    \"LR\": LogisticRegressionCV(\n",
    "        scoring='f1',\n",
    "        max_iter=5000,\n",
    "        penalty='l1',\n",
    "        solver='saga'\n",
    "    ),\n",
    "    \"SVM\": CalibratedLinearSVC(),\n",
    "    \"3-Layer-NeuralNetwork\": MLPClassifier(\n",
    "\n",
    "        hidden_layer_sizes=[int((len(dataframes['X_train_Original'].columns)*2)**0.5)]\n",
    "    ),\n",
    "    \"knn\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"GauNB\": GaussianNB(),\n",
    "    \"MixNB\": MixedNaiveBayes(\n",
    "        continuous_cols=continuous_cols, \n",
    "        categorical_cols=categorical_cols\n",
    "    ),\n",
    "    \"LDA\": LinearDiscriminantAnalysis(),\n",
    "    \"QDA\": QuadraticDiscriminantAnalysis()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, models, dataframes, transformation_name='BoxCox', epochs=1, debug=False):\n",
    "        self.models = models\n",
    "        self.dataframes = dataframes\n",
    "        self.transformation_name = transformation_name\n",
    "        self.epochs = epochs\n",
    "        self.debug = debug\n",
    "        self.performance_metrics_df = None\n",
    "\n",
    "        self.X_train = dataframes['X_train_' + transformation_name]\n",
    "        self.X_test = dataframes['X_test_' + transformation_name]\n",
    "        self.y_train = dataframes['y_train']\n",
    "        self.y_test = dataframes['y_test']\n",
    "        self.X_combined = pd.concat([self.X_train, self.X_test], axis=0)\n",
    "        self.y_combined = pd.concat([self.y_train, self.y_test], axis=0)\n",
    "        self.feature_names = None\n",
    "\n",
    "        self.folds_performance_metrics = []\n",
    "        self.folds_confusion_matrices = []\n",
    "        self.lr_coefs = []\n",
    "        self.svm_coefs = []\n",
    "\n",
    "    def undersample_train_data(self, X_train, y_train):\n",
    "        X_train['target'] = y_train\n",
    "        class_0 = X_train[y_train == 0]\n",
    "        class_1 = X_train[y_train == 1]\n",
    "\n",
    "        class_0_undersampled = resample(class_0, replace=False, n_samples=len(class_1), random_state=69)\n",
    "        X_train = pd.concat([class_0_undersampled, class_1])\n",
    "        y_train = X_train['target']\n",
    "\n",
    "        return X_train.drop(columns=['target']), y_train\n",
    "\n",
    "    def apply_SMOTE(self, X_train, y_train):\n",
    "        sm = SMOTE(random_state=69)\n",
    "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "        return X_train, y_train\n",
    "\n",
    "    def scale_features(self, X_train, X_test):\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.set_output(transform='pandas')\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        return X_train, X_test\n",
    "\n",
    "    def fit_models(self, APPLY_SMOTE_TO_TRAIN_DATA=False, \n",
    "                   UNDERSAMPLE_TRAIN_DATA=True, STAND_FEATURES=True,\n",
    "                   custom_features=None):\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=self.epochs, shuffle=True, random_state=69)\n",
    "        for i, (train_idx, test_idx) in enumerate(skf.split(self.X_combined, self.y_combined)):\n",
    "            print(f\"Starting fold {i + 1}/{self.epochs}...\\n\")\n",
    "\n",
    "            self.X_train = self.X_combined.iloc[train_idx]\n",
    "            self.X_test = self.X_combined.iloc[test_idx]\n",
    "            self.y_train = self.y_combined.iloc[train_idx]\n",
    "            self.y_test = self.y_combined.iloc[test_idx]\n",
    "\n",
    "            performance_metrics = []\n",
    "            confusion_matrixs = {}        \n",
    "\n",
    "            if APPLY_SMOTE_TO_TRAIN_DATA:\n",
    "                print(\"SMOTE train data applied.\\n\")\n",
    "            if STAND_FEATURES:\n",
    "                print(\"Standardized features applied.\\n\")\n",
    "            if UNDERSAMPLE_TRAIN_DATA:\n",
    "                print(\"Undersample train data applied.\\n\")\n",
    "\n",
    "            if UNDERSAMPLE_TRAIN_DATA:\n",
    "                self.X_train, self.y_train = self.undersample_train_data(self.X_train, self.y_train)\n",
    "\n",
    "            if APPLY_SMOTE_TO_TRAIN_DATA:\n",
    "                self.X_train, self.y_train = self.apply_SMOTE(self.X_train, self.y_train)\n",
    "\n",
    "            if 'target' in self.X_train.columns:\n",
    "                self.X_train = self.X_train.drop(columns=['target'])\n",
    "            if 'target' in self.X_test.columns:\n",
    "                self.X_test = self.X_test.drop(columns=['target'])\n",
    "\n",
    "            if STAND_FEATURES:\n",
    "                self.X_train, self.X_test = self.scale_features(self.X_train, self.X_test)\n",
    "\n",
    "            if custom_features is not None:\n",
    "                self.X_train = self.X_train[custom_features]\n",
    "                self.X_test = self.X_test[custom_features]\n",
    "\n",
    "                # for naive bayes, find continuous columns from custom features\n",
    "                self.models['MixNB'].continuous_cols = [\n",
    "                    col for col in self.models['MixNB'].continuous_cols if col in custom_features\n",
    "                ]\n",
    "                self.models['MixNB'].categorical_cols = [\n",
    "                    col for col in self.models['MixNB'].categorical_cols if col in custom_features\n",
    "                ]\n",
    "                \n",
    "            self.feature_names = self.X_train.columns.tolist()\n",
    "\n",
    "            self.y_train, self.y_test = self.y_train.squeeze(), self.y_test.squeeze()\n",
    "\n",
    "            for name, model in self.models.items():\n",
    "                print(f'Fitting {name}.')\n",
    "\n",
    "                if self.debug:\n",
    "                    print(f\"X_train median:\\n{self.X_train.median()}\\n\")\n",
    "                    print(f\"X_train std:\\n{self.X_train.std()}\\n\")\n",
    "                    print(f\"y_train distribution:\\n{self.y_train.value_counts(normalize=True)}\")\n",
    "                    print(f\"y_test distribution:\\n{self.y_test.value_counts(normalize=True)}\")\n",
    "\n",
    "                model.fit(self.X_train, self.y_train)\n",
    "                y_pred = model.predict(self.X_test)\n",
    "                y_prob = model.predict_proba(self.X_test)[:, -1]\n",
    "\n",
    "                if name == 'LR':\n",
    "                    self.lr_coefs.append(model.coef_[0])\n",
    "                elif name == 'SVM':\n",
    "                    self.svm_coefs.append(model.coef_[0])\n",
    "                    \n",
    "                metrics = {\n",
    "                    \"Model\": name,\n",
    "                    \"Accuracy\": accuracy_score(self.y_test, y_pred),\n",
    "                    \"Precision\": precision_score(self.y_test, y_pred),\n",
    "                    \"Recall\": recall_score(self.y_test, y_pred),\n",
    "                    \"F1 Score\": f1_score(self.y_test, y_pred),\n",
    "                    \"AUROC\": roc_auc_score(self.y_test, y_prob)\n",
    "                }\n",
    "\n",
    "                performance_metrics.append(metrics)\n",
    "\n",
    "                cm = confusion_matrix(self.y_test, y_pred)\n",
    "                confusion_matrixs[name] = cm\n",
    "                #print(f'Confusion Matrix for {name}:\\n{cm}\\n')\n",
    "\n",
    "            self.performance_metrics_df = pd.DataFrame(performance_metrics)\n",
    "            #print(self.performance_metrics_df)\n",
    "            print(f'Completed fold {i + 1}/{self.epochs}\\n')\n",
    "            self.folds_performance_metrics.append(self.performance_metrics_df)\n",
    "            self.folds_confusion_matrices.append(confusion_matrixs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fold 1/5...\n",
      "\n",
      "SMOTE train data applied.\n",
      "\n",
      "Standardized features applied.\n",
      "\n",
      "Fitting LR.\n",
      "Fitting SVM.\n",
      "Fitting 3-Layer-NeuralNetwork.\n",
      "Fitting knn.\n",
      "Fitting GauNB.\n",
      "Fitting MixNB.\n",
      "Fitting LDA.\n",
      "Fitting QDA.\n",
      "Completed fold 1/5\n",
      "\n",
      "Starting fold 2/5...\n",
      "\n",
      "SMOTE train data applied.\n",
      "\n",
      "Standardized features applied.\n",
      "\n",
      "Fitting LR.\n",
      "Fitting SVM.\n",
      "Fitting 3-Layer-NeuralNetwork.\n",
      "Fitting knn.\n",
      "Fitting GauNB.\n",
      "Fitting MixNB.\n",
      "Fitting LDA.\n",
      "Fitting QDA.\n",
      "Completed fold 2/5\n",
      "\n",
      "Starting fold 3/5...\n",
      "\n",
      "SMOTE train data applied.\n",
      "\n",
      "Standardized features applied.\n",
      "\n",
      "Fitting LR.\n",
      "Fitting SVM.\n",
      "Fitting 3-Layer-NeuralNetwork.\n",
      "Fitting knn.\n",
      "Fitting GauNB.\n",
      "Fitting MixNB.\n",
      "Fitting LDA.\n",
      "Fitting QDA.\n",
      "Completed fold 3/5\n",
      "\n",
      "Starting fold 4/5...\n",
      "\n",
      "SMOTE train data applied.\n",
      "\n",
      "Standardized features applied.\n",
      "\n",
      "Fitting LR.\n",
      "Fitting SVM.\n",
      "Fitting 3-Layer-NeuralNetwork.\n",
      "Fitting knn.\n",
      "Fitting GauNB.\n",
      "Fitting MixNB.\n",
      "Fitting LDA.\n",
      "Fitting QDA.\n",
      "Completed fold 4/5\n",
      "\n",
      "Starting fold 5/5...\n",
      "\n",
      "SMOTE train data applied.\n",
      "\n",
      "Standardized features applied.\n",
      "\n",
      "Fitting LR.\n",
      "Fitting SVM.\n",
      "Fitting 3-Layer-NeuralNetwork.\n",
      "Fitting knn.\n",
      "Fitting GauNB.\n",
      "Fitting MixNB.\n",
      "Fitting LDA.\n",
      "Fitting QDA.\n",
      "Completed fold 5/5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the ModelTrainer class\n",
    "trainer = ModelTrainer(models=models, dataframes=dataframes, transformation_name='BoxCox', epochs=5, debug=False)\n",
    "\n",
    "# Fit models\n",
    "trainer.fit_models(\n",
    "    APPLY_SMOTE_TO_TRAIN_DATA=True,\n",
    "    UNDERSAMPLE_TRAIN_DATA=False,\n",
    "    STAND_FEATURES=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitted coefficients interpretation (evaluation metric in permutation importance: f1 score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe extract some incorrectly classified samples and visualize how the factors impacted the final classification?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
